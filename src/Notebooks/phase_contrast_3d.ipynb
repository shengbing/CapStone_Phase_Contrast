{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80dc1aaa-8285-41e0-ad24-66ec573a2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv3D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling3D,\n",
    "    Softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "013498ec-15cb-4f73-b79a-40eb21f3cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.4'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23982acf-0300-4994-8bb2-014d4c5fa726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f9ee40b-b9a8-4f20-a2ee-888ecfddf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    294 Arterial\n",
      "    132 Late\n",
      "    152 Non-Contrast\n",
      "     56 Venous\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls /home/jupyter/asl-ml-immersion/notebooks/capstone_project/train-3d-npy | cut -d\"_\" -f5 |sort |uniq -c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70583330-5d96-4b7d-b8fd-696c75f4aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_numeric = {\n",
    "    \"Arterial\": 0,\n",
    "    \"Late\": 1,\n",
    "    \"Non-Contrast\": 2,\n",
    "    \"Venous\": 3\n",
    "}\n",
    "\n",
    "numeric_to_labels = {\n",
    "    0:   \"Arterial\",\n",
    "    1:   \"Late\",    \n",
    "    2:   \"Non-Contrast\",    \n",
    "    3:  \"Venous\"\n",
    "}\n",
    "\n",
    "\n",
    "#    294 Arterial\n",
    "#     132 Late\n",
    "#     152 Non-Contrast\n",
    "#      56 Venous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ab0fc6f-53f8-4f3b-aeff-c961e5b8a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize(images):\n",
    "    \n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Reshape the images to add an extra dimension\n",
    "    images = images.reshape((images.shape[0], images.shape[1], images.shape[2], images.shape[3], 1))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    max_value = np.max(images)\n",
    "    images = images/max_value\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return images, max_value# Reload the images in case you run this cell multiple times\n",
    "\n",
    "def load_and_format_data_from_gcs(sample_dir):\n",
    "    # sample_dir=\"gs://capstone-datasets/train_3d.csv\"\n",
    "    file_list = file_io.read_file_to_string(sample_dir).split(\"\\n\")\n",
    "    images = np.array([np.load(BytesIO(file_io.read_file_to_string(file, binary_mode=True)))\n",
    "                       for file in file_list if file])\n",
    "    labels = np.array([os.path.basename(file).split(\"_\")[4] for file in file_list if file])\n",
    "    labels = np.array([labels_to_numeric[label] for label in labels])\n",
    "    one_hots = to_categorical(labels)\n",
    "\n",
    "    images_tranformed, max_value = reshape_and_normalize(images)\n",
    "    return images_tranformed, one_hots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16e69b1b-7039-46ae-aa3f-c20fbd772add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (634, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case you run this cell multiple times\n",
    "training_sample_dir = \"gs://capstone-datasets/train_3d.csv\"\n",
    "training_images, one_hots = load_and_format_data_from_gcs(training_sample_dir)\n",
    "\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb4ef9b6-858c-4bd7-acd7-20af994a6afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (90, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case you run this cell multiple times\n",
    "valid_sample_dir = \"gs://capstone-datasets/valid_3d.csv\"\n",
    "\n",
    "\n",
    "# Apply your function\n",
    "valid_images, one_hots_valid = load_and_format_data_from_gcs(valid_sample_dir)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(valid_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {valid_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {valid_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2869c62f-bc9b-4b80-95be-6da10499632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Define the method that checks the accuracy at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') > 0.995:\n",
    "            print(\"Reached 99.5% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "            \n",
    "            \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81e09c4e-ded8-423a-a313-88f09cd33b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # hub.KerasLayer(\"https://tfhub.dev/google/HRNet/scannet-hrnetv2-w48/1\", trainable=False),\n",
    "        # tf.keras.layers.Dropout(rate=0.2)\n",
    "        tf.keras.layers.Conv3D(16, 3, activation='relu',input_shape=training_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2), padding='valid'),\n",
    "        tf.keras.layers.Conv3D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=tf.keras.activations.relu, kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(64, activation=tf.keras.activations.relu, kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dropout(rate=0.20),\n",
    "        tf.keras.layers.Dense(4),\n",
    "        tf.keras.layers.Softmax()\n",
    "        \n",
    "      \n",
    "      \n",
    "      \n",
    "    ])\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3533d362-97e7-4fbc-803d-8c40d5e4d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convolutional_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c74435c4-aead-4f88-986d-4e0882adbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build(input_shape=training_images.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f7d44a0-40d1-4f10-bd18-ab78a61103fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_2 (Conv3D)           (None, 30, 126, 126, 16)  448       \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 15, 63, 63, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 13, 61, 61, 32)    13856     \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 6, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 172800)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                11059264  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,077,988\n",
      "Trainable params: 11,077,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46e9dd33-53f7-4d44-abf1-0e9bd155b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "319234dd-299d-497c-8dcf-b601423fa198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 18:53:48.458749: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1329594368 exceeds 10% of free system memory.\n",
      "2023-03-28 18:53:49.244088: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1329594368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 6/20 [========>.....................] - ETA: 4s - loss: 13.9538 - accuracy: 0.3177WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1024s vs `on_train_batch_end` time: 0.1885s). Check your callbacks.\n",
      "20/20 [==============================] - 7s 325ms/step - loss: 10.3400 - accuracy: 0.4290 - val_loss: 7.0907 - val_accuracy: 0.4667\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 6.1471 - accuracy: 0.4621 - val_loss: 5.2264 - val_accuracy: 0.4667\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 4.7527 - accuracy: 0.4653 - val_loss: 4.3036 - val_accuracy: 0.4778\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 3.9393 - accuracy: 0.4590 - val_loss: 3.5965 - val_accuracy: 0.5111\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 3.3012 - accuracy: 0.5047 - val_loss: 3.0069 - val_accuracy: 0.6111\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 6s 313ms/step - loss: 2.8762 - accuracy: 0.5300 - val_loss: 2.6440 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 6s 313ms/step - loss: 2.4682 - accuracy: 0.5946 - val_loss: 2.3539 - val_accuracy: 0.5000\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 2.1986 - accuracy: 0.6025 - val_loss: 2.0203 - val_accuracy: 0.6222\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 2.0290 - accuracy: 0.6088 - val_loss: 1.9477 - val_accuracy: 0.6333\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 1.7439 - accuracy: 0.6309 - val_loss: 1.7038 - val_accuracy: 0.7111\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 1.5170 - accuracy: 0.7224 - val_loss: 1.4713 - val_accuracy: 0.7222\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 1.4333 - accuracy: 0.7161 - val_loss: 1.4489 - val_accuracy: 0.6556\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 1.3340 - accuracy: 0.7208 - val_loss: 1.3660 - val_accuracy: 0.7222\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 1.1913 - accuracy: 0.7461 - val_loss: 1.3458 - val_accuracy: 0.6667\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 1.0856 - accuracy: 0.7492 - val_loss: 1.3419 - val_accuracy: 0.6444\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 1.0917 - accuracy: 0.7823 - val_loss: 1.2964 - val_accuracy: 0.7222\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 1.1177 - accuracy: 0.7760 - val_loss: 1.2748 - val_accuracy: 0.6222\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 1.0855 - accuracy: 0.7445 - val_loss: 1.2983 - val_accuracy: 0.5667\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.9705 - accuracy: 0.7823 - val_loss: 1.0649 - val_accuracy: 0.7889\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.8425 - accuracy: 0.8438 - val_loss: 1.0036 - val_accuracy: 0.7222\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.7871 - accuracy: 0.8423 - val_loss: 1.1744 - val_accuracy: 0.6667\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.7659 - accuracy: 0.8659 - val_loss: 1.0748 - val_accuracy: 0.7222\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.7559 - accuracy: 0.8675 - val_loss: 1.1741 - val_accuracy: 0.6667\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.7736 - accuracy: 0.8502 - val_loss: 1.1559 - val_accuracy: 0.7222\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.7187 - accuracy: 0.8707 - val_loss: 1.1324 - val_accuracy: 0.7111\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 0.7235 - accuracy: 0.8596 - val_loss: 1.1588 - val_accuracy: 0.6444\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.8994 - accuracy: 0.8044 - val_loss: 1.0395 - val_accuracy: 0.7667\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 0.7177 - accuracy: 0.8754 - val_loss: 0.9899 - val_accuracy: 0.7778\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.6482 - accuracy: 0.9006 - val_loss: 1.0521 - val_accuracy: 0.7000\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.6115 - accuracy: 0.9227 - val_loss: 1.0728 - val_accuracy: 0.6889\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.5748 - accuracy: 0.9464 - val_loss: 1.1816 - val_accuracy: 0.6778\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.5208 - accuracy: 0.9511 - val_loss: 1.3193 - val_accuracy: 0.7000\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.5417 - accuracy: 0.9416 - val_loss: 1.0415 - val_accuracy: 0.7000\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.5328 - accuracy: 0.9243 - val_loss: 1.0750 - val_accuracy: 0.7222\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.5326 - accuracy: 0.9306 - val_loss: 1.0579 - val_accuracy: 0.7000\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.4826 - accuracy: 0.9669 - val_loss: 1.1311 - val_accuracy: 0.6778\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.4528 - accuracy: 0.9558 - val_loss: 1.0985 - val_accuracy: 0.7333\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.5249 - accuracy: 0.9211 - val_loss: 1.3017 - val_accuracy: 0.6333\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.4903 - accuracy: 0.9495 - val_loss: 1.1212 - val_accuracy: 0.6333\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.4792 - accuracy: 0.9432 - val_loss: 1.0823 - val_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=training_images, y=one_hots, validation_data=(valid_images,one_hots_valid), epochs=40, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09c2f9a1-e463-4425-9b7d-111254f55010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0adf82d-3532-4b72-9111-b841f094fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (634, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n",
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (90, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n",
      "Here is our model so far:\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 126, 126, 16)  448       \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 63, 63, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 13, 61, 61, 32)    13856     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 172800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11059264  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,077,988\n",
      "Trainable params: 11,077,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 19:52:27.434116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.563318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.565077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.606814: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 19:52:27.607606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.609504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.611203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.124758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.126715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.128431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.131140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 199 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2023-03-28 19:52:29.186270: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 199.50M (209190912 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/trainer/task.py\", line 78, in <module>\n",
      "    model.train_and_evaluate(arguments)\n",
      "  File \"/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/trainer/model.py\", line 147, in train_and_evaluate\n",
      "    callbacks=[callbacks, cp_callback, HPTCallback()])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "numpy.core._exceptions.MemoryError: Unable to allocate 1.24 GiB for an array with shape (634, 32, 128, 128, 1) and data type float32\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n\\n\\nBUCKET=capstone-datasets\\nOUTDIR=phase_contrast_trained\\nrm -rf ${OUTDIR}\\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\\npython3 -m trainer.task \\\\\\n    --train_data_path=gs://${BUCKET}/train_3d.csv \\\\\\n    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\\\\n    --output_dir=${OUTDIR} \\\\\\n    --num_epochs=1 \\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32m/var/tmp/ipykernel_28033/1402456186.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_cell_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'bash'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m''\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'\\n\\n\\nBUCKET=capstone-datasets\\nOUTDIR=phase_contrast_trained\\nrm -rf ${OUTDIR}\\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\\npython3 -m trainer.task \\\\\\n    --train_data_path=gs://${BUCKET}/train_3d.csv \\\\\\n    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\\\\n    --output_dir=${OUTDIR} \\\\\\n    --num_epochs=1 \\n'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mrun_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2471\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuiltin_trap\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2472\u001B[0m                 \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmagic_arg_s\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2473\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2474\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2475\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/magics/script.py\u001B[0m in \u001B[0;36mnamed_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m                 \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscript\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshebang\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m         \u001B[0;31m# write a basic docstring:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/decorator.py\u001B[0m in \u001B[0;36mfun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkwsyntax\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 232\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcaller\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mextras\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    233\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m     \u001B[0mfun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__doc__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/magic.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(f, *a, **k)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;31m# but it's overkill for just that one bit of state.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mmagic_deco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/magics/script.py\u001B[0m in \u001B[0;36mshebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    243\u001B[0m             \u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstderr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflush\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_error\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 245\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mCalledProcessError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturncode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstderr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_script\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcell\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mto_close\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'\\n\\n\\nBUCKET=capstone-datasets\\nOUTDIR=phase_contrast_trained\\nrm -rf ${OUTDIR}\\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\\npython3 -m trainer.task \\\\\\n    --train_data_path=gs://${BUCKET}/train_3d.csv \\\\\\n    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\\\\n    --output_dir=${OUTDIR} \\\\\\n    --num_epochs=1 \\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "\n",
    "BUCKET=capstone-datasets\n",
    "OUTDIR=phase_contrast_trained\n",
    "rm -rf ${OUTDIR}\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\n",
    "python3 -m trainer.task \\\n",
    "    --train_data_path=gs://${BUCKET}/train_3d.csv \\\n",
    "    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\n",
    "    --output_dir=${OUTDIR} \\\n",
    "    --num_epochs=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966a82a5-10d3-4dd5-ab92-ba8f722e5307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* containerization_local\n",
      "  local_container\n",
      "  main\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aeabbc9-af27-414a-9b0d-b648fadc91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'containerization_local'\n",
      "Your branch is ahead of 'origin/feature/containerization_shengbing' by 2 commits.\n",
      "  (use \"git push\" to publish your local commits)\n"
     ]
    }
   ],
   "source": [
    "!git checkout containerization_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3071e466-50b0-420a-abb8-967821fbb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src\n",
    "python /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/setup.py sdist --formats=gztar\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pwd\n",
    "ls dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "BUCKET=capstone-datasets\n",
    "gsutil cp /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/dist/ct_phase_contrast_trainer-0.1.tar.gz gs://${BUCKET}/ct_phase_contrast/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!ls /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/dist/ct_phase_contrast_trainer-0.1.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "BUCKET=capstone-datasets\n",
    "gsutil ls gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd\n",
    "gsutil cp gs://capstone-datasets/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz  /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/Notebooks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "zcat /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/Notebooks/ct_phase_contrast_trainer-0.1.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "BUCKET=capstone-datasets\n",
    "gsutil ls gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project\n",
    "mkdir ct_phase_contrast_trained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "** train on Vertex AI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-standard-4\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.2\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.2\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "# gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam_1.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam_1.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project\n",
    "mkdir ct_phase_contrast_trained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "** train on Vertex AI"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-standard-4\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.2\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.2\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "# gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam_1.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam_1.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "** using GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-highmem-16\n",
    "    acceleratorType: NVIDIA_TESLA_P100\n",
    "    acceleratorCount: 2\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*** using GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "# gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam_1.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "        machineType: n1-highmem-16\n",
    "        acceleratorType: NVIDIA_TESLA_P100\n",
    "        acceleratorCount: 2\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam_1.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train using best hyperparameters:\n",
    "dropout_rate 0.05\n",
    "l2_regularization_lambda 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-highmem-16\n",
    "    acceleratorType: NVIDIA_TESLA_P100\n",
    "    acceleratorCount: 2\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\n",
    "    - --dropout_rate=0.05\n",
    "    - --l2_regularization_lambda=0.001\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir LOG_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47b2776e-221c-4e9e-b5dd-d4d04d054b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project\n",
    "mkdir ct_phase_contrast_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba063ff-b02e-478f-8e90-05ca9c56ba76",
   "metadata": {},
   "source": [
    "** train on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d67bc2e8-db43-42ea-9f89-afc087ef9b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/146339387885/locations/us-central1/customJobs/5331840158658461696] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/146339387885/locations/us-central1/customJobs/5331840158658461696\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/146339387885/locations/us-central1/customJobs/5331840158658461696\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-standard-4\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f8f6945-f086-4397-a4c6-d9da934e1612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-datasets-shengbing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://capstone-datasets-shengbing/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'capstone-datasets-shengbing' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Hyperparameter tuning job [3422595391630082048] submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai hp-tuning-jobs describe 3422595391630082048 --region=us-central1\n",
      "\n",
      "Job State: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.2\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.2\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ef1ba4-c85e-47ca-9be1-bd0d6df428bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-datasets-shengbing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Hyperparameter tuning job [6218415966552850432] submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai hp-tuning-jobs describe 6218415966552850432 --region=us-central1\n",
      "\n",
      "Job State: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "# gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam_1.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "      machineType: n1-standard-8\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam_1.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b561b3-9339-4bff-8679-4fa9a7c42576",
   "metadata": {},
   "source": [
    "** using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "252488bf-210d-4bfa-9511-f57190fb589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/146339387885/locations/us-central1/customJobs/6488631944195080192] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/146339387885/locations/us-central1/customJobs/6488631944195080192\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/146339387885/locations/us-central1/customJobs/6488631944195080192\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-highmem-16\n",
    "    acceleratorType: NVIDIA_TESLA_P100\n",
    "    acceleratorCount: 2\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788eb3c3-ab8c-4ba0-974a-e7807a7d42f0",
   "metadata": {},
   "source": [
    "*** using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c8f4cdb-d9e0-4e30-a611-4d512593b7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-datasets-shengbing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "/usr/bin/../lib/google-cloud-sdk/lib/third_party/ruamel/yaml/constructor.py:283: DuplicateKeyFutureWarning: while constructing a mapping\n",
      "  in \"hyperparam_1.yaml\", line 22, column 5\n",
      "found duplicate key \"replicaCount\" with value \"1\" (original value: \"1\")\n",
      "  in \"hyperparam_1.yaml\", line 37, column 5\n",
      "\n",
      "To suppress this check see:\n",
      "    http://yaml.readthedocs.io/en/latest/api.html#duplicate-keys\n",
      "\n",
      "Duplicate keys will become an error in future releases, and are errors\n",
      "by default when using the new API.\n",
      "\n",
      "  warnings.warn(DuplicateKeyFutureWarning(*args))\n",
      "Hyperparameter tuning job [7282074719170330624] submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai hp-tuning-jobs describe 7282074719170330624 --region=us-central1\n",
      "\n",
      "Job State: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "DATA_BUCKET=capstone-datasets\n",
    "BUCKET=capstone-datasets-shengbing\n",
    "\n",
    "# gsutil mb -l $REGION gs://$BUCKET\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "BASE_OUTPUT_DIR=gs://${BUCKET}/ct_phase_contrast/hp_tuning_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_hpt_$TIMESTAMP\n",
    "\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${DATA_BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./hyperparam_1.yaml \"displayName: $JOB_NAME\n",
    "studySpec:\n",
    "  metrics:\n",
    "  - metricId: val_loss\n",
    "    goal: MINIMIZE\n",
    "  parameters:\n",
    "  - parameterId: dropout_rate\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  - parameterId: l2_regularization_lambda\n",
    "    doubleValueSpec:\n",
    "      minValue: 0.001\n",
    "      maxValue: 0.4\n",
    "    scaleType: UNIT_LOG_SCALE\n",
    "  algorithm: ALGORITHM_UNSPECIFIED # results in Bayesian optimization\n",
    "trialJobSpec:\n",
    "  baseOutputDirectory:\n",
    "    outputUriPrefix: $BASE_OUTPUT_DIR\n",
    "  workerPoolSpecs:\n",
    "  - machineSpec:\n",
    "        machineType: n1-highmem-16\n",
    "        acceleratorType: NVIDIA_TESLA_P100\n",
    "        acceleratorCount: 2\n",
    "    pythonPackageSpec:\n",
    "      executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "      packageUris:\n",
    "      - $PYTHON_PACKAGE_URI\n",
    "      pythonModule: $PYTHON_MODULE\n",
    "      args:\n",
    "        - --train_data_path=gs://${DATA_BUCKET}/train_3d.csv\n",
    "        - --eval_data_path=gs://${DATA_BUCKET}/valid_3d.csv\n",
    "        - --output_dir=$OUTDIR\n",
    "        - --num_epochs=40   \n",
    "    replicaCount: 1\"\n",
    "        \n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=hyperparam_1.yaml \\\n",
    "    --max-trial-count=20 \\\n",
    "    --parallel-trial-count=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94744fb1-4a62-4ffa-9e0a-c23de2af4a08",
   "metadata": {},
   "source": [
    "train using best hyperparameters:\n",
    "dropout_rate 0.05\n",
    "l2_regularization_lambda 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37d1d5c0-ac08-4029-8cb5-484062a0c1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capstone-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/146339387885/locations/us-central1/customJobs/5628549968483581952] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/146339387885/locations/us-central1/customJobs/5628549968483581952\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/146339387885/locations/us-central1/customJobs/5628549968483581952\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "echo $BUCKET\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-highmem-16\n",
    "    acceleratorType: NVIDIA_TESLA_P100\n",
    "    acceleratorCount: 2\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\n",
    "    - --dropout_rate=0.05\n",
    "    - --l2_regularization_lambda=0.001\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9649836-70ef-49e8-96e4-5ae691bdc512",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir LOG_DIR"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "uncertainty_aware_models_kernel",
   "name": "tf2-gpu.2-8.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m104"
  },
  "kernelspec": {
   "display_name": "uncertainty_aware_models_kernel",
   "language": "python",
   "name": "uncertainty_aware_models_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}