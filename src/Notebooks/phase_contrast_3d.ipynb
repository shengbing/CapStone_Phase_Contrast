{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80dc1aaa-8285-41e0-ad24-66ec573a2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv3D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    MaxPooling3D,\n",
    "    Softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "013498ec-15cb-4f73-b79a-40eb21f3cdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.4'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23982acf-0300-4994-8bb2-014d4c5fa726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0699a71-63ca-4d59-b8df-d2732ae0af83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bdcd92-97c0-491c-aaae-078050bf95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f7a92ae-e4a0-481e-aa31-9c62ddbc8911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy file from GCS to this this notebook\n",
    "# two folders are created:\n",
    "# \n",
    "# /home/jupyter/asl-ml-immersion/notebooks/capstone_project/valid-3d-npy\n",
    "#/home/jupyter/asl-ml-immersion/notebooks/capstone_project/train-3d-npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb15403-fc76-47bf-9c9d-9c1d06c77b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f9ee40b-b9a8-4f20-a2ee-888ecfddf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    294 Arterial\n",
      "    132 Late\n",
      "    152 Non-Contrast\n",
      "     56 Venous\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls /home/jupyter/asl-ml-immersion/notebooks/capstone_project/train-3d-npy | cut -d\"_\" -f5 |sort |uniq -c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e904e-e49a-4365-8e4f-0a2ea4896d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55c3ca-48cf-4619-8229-9ebf17d25417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b279719-686e-402c-9bec-59daee620d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8d4bb-9611-4113-bd78-e9f28061adf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda7dfc-e4b8-4a0f-a8f5-7ed9d2a4fd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dea378-5429-4d9b-8e3b-64bd1aeaa068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70583330-5d96-4b7d-b8fd-696c75f4aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_numeric = {\n",
    "    \"Arterial\": 0,\n",
    "    \"Late\": 1,\n",
    "    \"Non-Contrast\": 2,\n",
    "    \"Venous\": 3\n",
    "}\n",
    "\n",
    "numeric_to_labels = {\n",
    "    0:   \"Arterial\",\n",
    "    1:   \"Late\",    \n",
    "    2:   \"Non-Contrast\",    \n",
    "    3:  \"Venous\"\n",
    "}\n",
    "\n",
    "\n",
    "#    294 Arterial\n",
    "#     132 Late\n",
    "#     152 Non-Contrast\n",
    "#      56 Venous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de827c26-caca-43ef-927d-c335f003e676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b8348-f278-466f-9070-3b7dfb279260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79ce74-56e2-46d2-89bd-7966711e4a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ab0fc6f-53f8-4f3b-aeff-c961e5b8a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize(images):\n",
    "    \n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Reshape the images to add an extra dimension\n",
    "    images = images.reshape((images.shape[0], images.shape[1], images.shape[2], images.shape[3], 1))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    max_value = np.max(images)\n",
    "    images = images/max_value\n",
    "    \n",
    "    ### END CODE HERE\n",
    "\n",
    "    return images, max_value# Reload the images in case you run this cell multiple times\n",
    "\n",
    "def load_and_format_data_from_gcs(sample_dir):\n",
    "    # sample_dir=\"gs://capstone-datasets/train_3d.csv\"\n",
    "    file_list = file_io.read_file_to_string(sample_dir).split(\"\\n\")\n",
    "    images = np.array([np.load(BytesIO(file_io.read_file_to_string(file, binary_mode=True)))\n",
    "                       for file in file_list if file])\n",
    "    labels = np.array([os.path.basename(file).split(\"_\")[4] for file in file_list if file])\n",
    "    labels = np.array([labels_to_numeric[label] for label in labels])\n",
    "    one_hots = to_categorical(labels)\n",
    "\n",
    "    images_tranformed, max_value = reshape_and_normalize(images)\n",
    "    return images_tranformed, one_hots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16e69b1b-7039-46ae-aa3f-c20fbd772add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (634, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case you run this cell multiple times\n",
    "training_sample_dir = \"gs://capstone-datasets/train_3d.csv\"\n",
    "training_images, one_hots = load_and_format_data_from_gcs(training_sample_dir)\n",
    "\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb4ef9b6-858c-4bd7-acd7-20af994a6afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (90, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case you run this cell multiple times\n",
    "valid_sample_dir = \"gs://capstone-datasets/valid_3d.csv\"\n",
    "\n",
    "\n",
    "# Apply your function\n",
    "valid_images, one_hots_valid = load_and_format_data_from_gcs(valid_sample_dir)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(valid_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {valid_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {valid_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2869c62f-bc9b-4b80-95be-6da10499632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Define the method that checks the accuracy at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') > 0.995:\n",
    "            print(\"Reached 99.5% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "            \n",
    "            \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81e09c4e-ded8-423a-a313-88f09cd33b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # hub.KerasLayer(\"https://tfhub.dev/google/HRNet/scannet-hrnetv2-w48/1\", trainable=False),\n",
    "        # tf.keras.layers.Dropout(rate=0.2)\n",
    "        tf.keras.layers.Conv3D(16, 3, activation='relu',input_shape=training_images.shape[1:]),\n",
    "        tf.keras.layers.MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2), padding='valid'),\n",
    "        tf.keras.layers.Conv3D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation=tf.keras.activations.relu, kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(64, activation=tf.keras.activations.relu, kernel_regularizer=keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dropout(rate=0.20),\n",
    "        tf.keras.layers.Dense(4),\n",
    "        tf.keras.layers.Softmax()\n",
    "        \n",
    "      \n",
    "      \n",
    "      \n",
    "    ])\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3533d362-97e7-4fbc-803d-8c40d5e4d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convolutional_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c74435c4-aead-4f88-986d-4e0882adbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build(input_shape=training_images.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f7d44a0-40d1-4f10-bd18-ab78a61103fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_2 (Conv3D)           (None, 30, 126, 126, 16)  448       \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 15, 63, 63, 16)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 13, 61, 61, 32)    13856     \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 6, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 172800)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                11059264  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,077,988\n",
      "Trainable params: 11,077,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46e9dd33-53f7-4d44-abf1-0e9bd155b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "319234dd-299d-497c-8dcf-b601423fa198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 18:53:48.458749: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1329594368 exceeds 10% of free system memory.\n",
      "2023-03-28 18:53:49.244088: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1329594368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 6/20 [========>.....................] - ETA: 4s - loss: 13.9538 - accuracy: 0.3177WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1024s vs `on_train_batch_end` time: 0.1885s). Check your callbacks.\n",
      "20/20 [==============================] - 7s 325ms/step - loss: 10.3400 - accuracy: 0.4290 - val_loss: 7.0907 - val_accuracy: 0.4667\n",
      "Epoch 2/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 6.1471 - accuracy: 0.4621 - val_loss: 5.2264 - val_accuracy: 0.4667\n",
      "Epoch 3/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 4.7527 - accuracy: 0.4653 - val_loss: 4.3036 - val_accuracy: 0.4778\n",
      "Epoch 4/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 3.9393 - accuracy: 0.4590 - val_loss: 3.5965 - val_accuracy: 0.5111\n",
      "Epoch 5/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 3.3012 - accuracy: 0.5047 - val_loss: 3.0069 - val_accuracy: 0.6111\n",
      "Epoch 6/40\n",
      "20/20 [==============================] - 6s 313ms/step - loss: 2.8762 - accuracy: 0.5300 - val_loss: 2.6440 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "20/20 [==============================] - 6s 313ms/step - loss: 2.4682 - accuracy: 0.5946 - val_loss: 2.3539 - val_accuracy: 0.5000\n",
      "Epoch 8/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 2.1986 - accuracy: 0.6025 - val_loss: 2.0203 - val_accuracy: 0.6222\n",
      "Epoch 9/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 2.0290 - accuracy: 0.6088 - val_loss: 1.9477 - val_accuracy: 0.6333\n",
      "Epoch 10/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 1.7439 - accuracy: 0.6309 - val_loss: 1.7038 - val_accuracy: 0.7111\n",
      "Epoch 11/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 1.5170 - accuracy: 0.7224 - val_loss: 1.4713 - val_accuracy: 0.7222\n",
      "Epoch 12/40\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 1.4333 - accuracy: 0.7161 - val_loss: 1.4489 - val_accuracy: 0.6556\n",
      "Epoch 13/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 1.3340 - accuracy: 0.7208 - val_loss: 1.3660 - val_accuracy: 0.7222\n",
      "Epoch 14/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 1.1913 - accuracy: 0.7461 - val_loss: 1.3458 - val_accuracy: 0.6667\n",
      "Epoch 15/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 1.0856 - accuracy: 0.7492 - val_loss: 1.3419 - val_accuracy: 0.6444\n",
      "Epoch 16/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 1.0917 - accuracy: 0.7823 - val_loss: 1.2964 - val_accuracy: 0.7222\n",
      "Epoch 17/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 1.1177 - accuracy: 0.7760 - val_loss: 1.2748 - val_accuracy: 0.6222\n",
      "Epoch 18/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 1.0855 - accuracy: 0.7445 - val_loss: 1.2983 - val_accuracy: 0.5667\n",
      "Epoch 19/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.9705 - accuracy: 0.7823 - val_loss: 1.0649 - val_accuracy: 0.7889\n",
      "Epoch 20/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.8425 - accuracy: 0.8438 - val_loss: 1.0036 - val_accuracy: 0.7222\n",
      "Epoch 21/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.7871 - accuracy: 0.8423 - val_loss: 1.1744 - val_accuracy: 0.6667\n",
      "Epoch 22/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.7659 - accuracy: 0.8659 - val_loss: 1.0748 - val_accuracy: 0.7222\n",
      "Epoch 23/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.7559 - accuracy: 0.8675 - val_loss: 1.1741 - val_accuracy: 0.6667\n",
      "Epoch 24/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.7736 - accuracy: 0.8502 - val_loss: 1.1559 - val_accuracy: 0.7222\n",
      "Epoch 25/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.7187 - accuracy: 0.8707 - val_loss: 1.1324 - val_accuracy: 0.7111\n",
      "Epoch 26/40\n",
      "20/20 [==============================] - 6s 307ms/step - loss: 0.7235 - accuracy: 0.8596 - val_loss: 1.1588 - val_accuracy: 0.6444\n",
      "Epoch 27/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.8994 - accuracy: 0.8044 - val_loss: 1.0395 - val_accuracy: 0.7667\n",
      "Epoch 28/40\n",
      "20/20 [==============================] - 6s 306ms/step - loss: 0.7177 - accuracy: 0.8754 - val_loss: 0.9899 - val_accuracy: 0.7778\n",
      "Epoch 29/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.6482 - accuracy: 0.9006 - val_loss: 1.0521 - val_accuracy: 0.7000\n",
      "Epoch 30/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.6115 - accuracy: 0.9227 - val_loss: 1.0728 - val_accuracy: 0.6889\n",
      "Epoch 31/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.5748 - accuracy: 0.9464 - val_loss: 1.1816 - val_accuracy: 0.6778\n",
      "Epoch 32/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.5208 - accuracy: 0.9511 - val_loss: 1.3193 - val_accuracy: 0.7000\n",
      "Epoch 33/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.5417 - accuracy: 0.9416 - val_loss: 1.0415 - val_accuracy: 0.7000\n",
      "Epoch 34/40\n",
      "20/20 [==============================] - 6s 311ms/step - loss: 0.5328 - accuracy: 0.9243 - val_loss: 1.0750 - val_accuracy: 0.7222\n",
      "Epoch 35/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.5326 - accuracy: 0.9306 - val_loss: 1.0579 - val_accuracy: 0.7000\n",
      "Epoch 36/40\n",
      "20/20 [==============================] - 6s 309ms/step - loss: 0.4826 - accuracy: 0.9669 - val_loss: 1.1311 - val_accuracy: 0.6778\n",
      "Epoch 37/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.4528 - accuracy: 0.9558 - val_loss: 1.0985 - val_accuracy: 0.7333\n",
      "Epoch 38/40\n",
      "20/20 [==============================] - 6s 310ms/step - loss: 0.5249 - accuracy: 0.9211 - val_loss: 1.3017 - val_accuracy: 0.6333\n",
      "Epoch 39/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.4903 - accuracy: 0.9495 - val_loss: 1.1212 - val_accuracy: 0.6333\n",
      "Epoch 40/40\n",
      "20/20 [==============================] - 6s 308ms/step - loss: 0.4792 - accuracy: 0.9432 - val_loss: 1.0823 - val_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=training_images, y=one_hots, validation_data=(valid_images,one_hots_valid), epochs=40, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09c2f9a1-e463-4425-9b7d-111254f55010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0adf82d-3532-4b72-9111-b841f094fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (634, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n",
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (90, 32, 128, 128, 1)\n",
      "\n",
      "Shape of one image after reshaping: (32, 128, 128, 1)\n",
      "Here is our model so far:\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 126, 126, 16)  448       \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 63, 63, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 13, 61, 61, 32)    13856     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 30, 30, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 172800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11059264  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,077,988\n",
      "Trainable params: 11,077,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 19:52:27.434116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.563318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.565077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.606814: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 19:52:27.607606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.609504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:27.611203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.124758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.126715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.128431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 19:52:29.131140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 199 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2023-03-28 19:52:29.186270: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 199.50M (209190912 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/trainer/task.py\", line 78, in <module>\n",
      "    model.train_and_evaluate(arguments)\n",
      "  File \"/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/trainer/model.py\", line 147, in train_and_evaluate\n",
      "    callbacks=[callbacks, cp_callback, HPTCallback()])\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 102, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "numpy.core._exceptions.MemoryError: Unable to allocate 1.24 GiB for an array with shape (634, 32, 128, 128, 1) and data type float32\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\n\\n\\nBUCKET=capstone-datasets\\nOUTDIR=phase_contrast_trained\\nrm -rf ${OUTDIR}\\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\\npython3 -m trainer.task \\\\\\n    --train_data_path=gs://${BUCKET}/train_3d.csv \\\\\\n    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\\\\n    --output_dir=${OUTDIR} \\\\\\n    --num_epochs=1 \\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_28033/1402456186.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\n\\nBUCKET=capstone-datasets\\nOUTDIR=phase_contrast_trained\\nrm -rf ${OUTDIR}\\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\\npython3 -m trainer.task \\\\\\n    --train_data_path=gs://${BUCKET}/train_3d.csv \\\\\\n    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\\\\n    --output_dir=${OUTDIR} \\\\\\n    --num_epochs=1 \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asl-ml-immersion/notebooks/uncertainty_aware_models/uncertainty_aware_models_kernel/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\n\\n\\nBUCKET=capstone-datasets\\nOUTDIR=phase_contrast_trained\\nrm -rf ${OUTDIR}\\nexport PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\\npython3 -m trainer.task \\\\\\n    --train_data_path=gs://${BUCKET}/train_3d.csv \\\\\\n    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\\\\n    --output_dir=${OUTDIR} \\\\\\n    --num_epochs=1 \\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "\n",
    "\n",
    "BUCKET=capstone-datasets\n",
    "OUTDIR=phase_contrast_trained\n",
    "rm -rf ${OUTDIR}\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/babyweight\n",
    "python3 -m trainer.task \\\n",
    "    --train_data_path=gs://${BUCKET}/train_3d.csv \\\n",
    "    --eval_data_path=gs://${BUCKET}/valid_3d.csv \\\n",
    "    --output_dir=${OUTDIR} \\\n",
    "    --num_epochs=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "966a82a5-10d3-4dd5-ab92-ba8f722e5307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* containerization_local\n",
      "  local_container\n",
      "  main\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3aeabbc9-af27-414a-9b0d-b648fadc91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'containerization_local'\n",
      "Your branch is up to date with 'origin/feature/containerization_shengbing'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout containerization_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3071e466-50b0-420a-abb8-967821fbb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "597b7511-7ac0-4e22-a7f0-e93c27ddc0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "creating ct_phase_contrast_trainer.egg-info\n",
      "writing ct_phase_contrast_trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to ct_phase_contrast_trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to ct_phase_contrast_trainer.egg-info/top_level.txt\n",
      "writing manifest file 'ct_phase_contrast_trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'ct_phase_contrast_trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'ct_phase_contrast_trainer.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating ct_phase_contrast_trainer-0.1\n",
      "creating ct_phase_contrast_trainer-0.1/ct_phase_contrast_trainer.egg-info\n",
      "creating ct_phase_contrast_trainer-0.1/trainer\n",
      "copying files to ct_phase_contrast_trainer-0.1...\n",
      "copying setup.py -> ct_phase_contrast_trainer-0.1\n",
      "copying ct_phase_contrast_trainer.egg-info/PKG-INFO -> ct_phase_contrast_trainer-0.1/ct_phase_contrast_trainer.egg-info\n",
      "copying ct_phase_contrast_trainer.egg-info/SOURCES.txt -> ct_phase_contrast_trainer-0.1/ct_phase_contrast_trainer.egg-info\n",
      "copying ct_phase_contrast_trainer.egg-info/dependency_links.txt -> ct_phase_contrast_trainer-0.1/ct_phase_contrast_trainer.egg-info\n",
      "copying ct_phase_contrast_trainer.egg-info/top_level.txt -> ct_phase_contrast_trainer-0.1/ct_phase_contrast_trainer.egg-info\n",
      "copying trainer/__init__.py -> ct_phase_contrast_trainer-0.1/trainer\n",
      "copying trainer/model.py -> ct_phase_contrast_trainer-0.1/trainer\n",
      "copying trainer/task.py -> ct_phase_contrast_trainer-0.1/trainer\n",
      "Writing ct_phase_contrast_trainer-0.1/setup.cfg\n",
      "creating dist\n",
      "Creating tar archive\n",
      "removing 'ct_phase_contrast_trainer-0.1' (and everything under it)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python ./setup.py sdist --formats=gztar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4545b8df-a8a0-4d3f-bc97-f57a66e1d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src\n",
      "ct_phase_contrast_trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pwd\n",
    "ls dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f8f9e2e-27e8-4453-8eef-f0561c32c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/dist/ct_phase_contrast_trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  3.2 KiB/  3.2 KiB]                                                \n",
      "Operation completed over 1 objects/3.2 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BUCKET=capstone-datasets\n",
    "gsutil cp /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/dist/ct_phase_contrast_trainer-0.1.tar.gz gs://${BUCKET}/ct_phase_contrast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5279380b-ee76-492d-8fb0-9079aabfc6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/dist/ct_phase_contrast_trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls /home/jupyter/asl-ml-immersion/notebooks/capstone_project/CapStone_Phase_Contrast/src/dist/ct_phase_contrast_trainer-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "afb8b45b-b98f-4a33-8e99-534484586500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://capstone-datasets/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "BUCKET=capstone-datasets\n",
    "gsutil ls gs://${BUCKET}/ct_phase_contrast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47b2776e-221c-4e9e-b5dd-d4d04d054b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project\n",
    "mkdir ct_phase_contrast_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba063ff-b02e-478f-8e90-05ca9c56ba76",
   "metadata": {},
   "source": [
    "train on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bc2e8-db43-42ea-9f89-afc087ef9b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd /home/jupyter/asl-ml-immersion/notebooks/capstone_project/ct_phase_contrast_trained\n",
    "\n",
    "REGION=\"us-central1\"\n",
    "BUCKET=capstone-datasets\n",
    "\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/ct_phase_contrast/trained_model_$TIMESTAMP\n",
    "JOB_NAME=ct_phase_contrast_$TIMESTAMP\n",
    "\n",
    "PYTHON_PACKAGE_URI=gs://${BUCKET}/ct_phase_contrast/ct_phase_contrast_trainer-0.1.tar.gz\n",
    "PYTHON_PACKAGE_EXECUTOR_IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\"\n",
    "PYTHON_MODULE=trainer.task\n",
    "\n",
    "echo > ./config.yaml \"workerPoolSpecs:\n",
    "  machineSpec:\n",
    "    machineType: n1-standard-4\n",
    "  replicaCount: 1\n",
    "  pythonPackageSpec:\n",
    "    executorImageUri: $PYTHON_PACKAGE_EXECUTOR_IMAGE_URI\n",
    "    packageUris: $PYTHON_PACKAGE_URI\n",
    "    pythonModule: $PYTHON_MODULE\n",
    "    args:\n",
    "    - --train_data_path=gs://${BUCKET}/train_3d.csv\n",
    "    - --eval_data_path=gs://${BUCKET}/valid_3d.csv\n",
    "    - --output_dir=$OUTDIR\n",
    "    - --num_epochs=40\"\n",
    "\n",
    "\n",
    "gcloud ai custom-jobs create \\\n",
    "  --region=${REGION} \\\n",
    "  --display-name=$JOB_NAME \\\n",
    "  --config=config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8f6945-f086-4397-a4c6-d9da934e1612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "uncertainty_aware_models_kernel",
   "name": "tf2-gpu.2-8.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m104"
  },
  "kernelspec": {
   "display_name": "uncertainty_aware_models_kernel",
   "language": "python",
   "name": "uncertainty_aware_models_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
